{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперимент по построению третьего уровня иерархии\n",
    "\n",
    "Модель построена на данных \"Демо-корпус + Лента.ру\", предлагается как родительская модель верхнего уровня иерархии, хотя бы для первых экспериментов построения следующих уровней иерархии.  \n",
    "  \n",
    "Данные для построения модели можно взять в общей папке с данными на Google Drive: архив 1lvl.zip\n",
    "\n",
    "Рубрикатор верхнего уровня на 10 фиксированных категорий составляла Таснима Садекова (str12.01.94@gmail.com).  \n",
    "  \n",
    "Эксперименты по подбору гиперпараметров и измерению качества модели первого уровня (главным образом, точности классификации новостей с помощью модели) проводил Александр Романенко (angriff07@gmail.com).  \n",
    "\n",
    "Эксперименты по подбору гиперпараметров и измерению качества модели второго и третьего уровней (главным уровнем, визуального восприятия матрицы связей psi, когерентности и перплексии тем) проводил Артём Попов (artmes-07@mail.ru).\n",
    "\n",
    "Ниже представлен код самой модели, топ-слова, графики качества..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import time\n",
    "import os\n",
    "import codecs\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import sklearn.metrics\n",
    "\n",
    "import artm\n",
    "lc = artm.messages.ConfigureLoggingArgs()\n",
    "lc.log_dir=r'/home/arti32lehtonen/Other/python_files/bigartm_logs/'\n",
    "lib = artm.wrapper.LibArtm(logging_config=lc)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import rc\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/home/arti32lehtonen/Programs/aithea/tvcenter_new/sasha_scripts/tm_nlp/')\n",
    "from tools import helpers \n",
    "from tools import CollectionUCI\n",
    "from tools import ngrammer\n",
    "reload(helpers)\n",
    "reload(CollectionUCI)\n",
    "reload(ngrammer)\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'family': 'Arial',\n",
    "        'weight': 'normal'}\n",
    "rc('font', **font)\n",
    "\n",
    "def colorize_matrix(mat, row_names=None, column_names=None, cmap=plt.cm.Blues):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(mat, interpolation='nearest', cmap=cmap)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.set_xticklabels(['']+column_names)\n",
    "    ax.set_yticklabels(['']+row_names)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def calc_quality(theta, id2answers, cats_in_topic_order):\n",
    "    theta.index = cats_in_topic_order\n",
    "    true_answ = []\n",
    "    pred_answ = []\n",
    "    for doc_id,cat in id2answers.iteritems():\n",
    "        if not len(cat):\n",
    "            continue\n",
    "        pred_answ += [np.argmax(theta[doc_id])]\n",
    "        true_answ += [cat]        \n",
    "    P = sklearn.metrics.precision_recall_fscore_support(true_answ, pred_answ)[0]\n",
    "    R = sklearn.metrics.precision_recall_fscore_support(true_answ, pred_answ)[1]\n",
    "    F1 = sklearn.metrics.precision_recall_fscore_support(true_answ, pred_answ)[2]\n",
    "    supported = sklearn.metrics.precision_recall_fscore_support(true_answ, pred_answ)[3]\n",
    "    ACC1 = sklearn.metrics.accuracy_score(true_answ, pred_answ)\n",
    "    F1_micro = sklearn.metrics.f1_score(true_answ, pred_answ, average='micro')\n",
    "    F1_macro = sklearn.metrics.f1_score(true_answ, pred_answ, average='macro')\n",
    "    F1_weighted = sklearn.metrics.f1_score(true_answ, pred_answ, average='weighted')\n",
    "    return {'F1':F1,'P':P,'R':R,'ACC1':ACC1, 'F1_micro':F1_micro,'F1_macro':F1_macro,'F1_weighted':F1_weighted,'supported':supported,'ConfMat':sklearn.metrics.confusion_matrix(true_answ, pred_answ)}\n",
    "\n",
    "\n",
    "def figures(model):\n",
    "    x = range(model.num_phi_updates)[1:]\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(x, model.score_tracker['Perplexity'].value[1:], 'g-', linewidth=2, label=\"Perplexity\")\n",
    "    ax1.set_ylabel('Perplexity', color='g')\n",
    "    ax11 = ax1.twinx()\n",
    "    ax11.plot(x, model.score_tracker['SparsityPhiText'].value[1:], 'b--', linewidth=2, label=\"Phi\")\n",
    "    ax11.plot(x, model.score_tracker['SparsityTheta'].value[1:], 'r--', linewidth=2, label=\"Theta \")\n",
    "    ax11.set_ylabel('Ratio', color='r')\n",
    "    ax11.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=3, mode=\"expand\", borderaxespad=0.)\n",
    "    ax1.grid(True)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_path = '../data/trn/vw/data.vw.txt'\n",
    "#batches_train_path = '../batches/trn'\n",
    "batches_train_path = '../../../../Other/python_files/visartm/data/datasets/news_trn_vocab/batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(glob.glob(batches_train_path + \"/*.batch\")) < 1:\n",
    "    batch_vectorizer_train = artm.BatchVectorizer(data_path=data_train_path + '', collection_name='',\n",
    "                                            data_format='vowpal_wabbit', batch_size = 1000, \n",
    "                                            target_folder=batches_train_path)\n",
    "else:\n",
    "    batch_vectorizer_train = artm.BatchVectorizer(data_path=batches_train_path, \n",
    "                                            data_format='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dictionary = artm.Dictionary()\n",
    "\n",
    "if len(glob.glob(batches_train_path + \"/*.dict\")) < 1:\n",
    "    my_dictionary.gather(data_path=batches_train_path, vocab_file_path=data_train_path + '/vocab.mediaplanning.txt')\n",
    "    my_dictionary.save(dictionary_path=batches_train_path + '/mediaplanning_dictionary')\n",
    "\n",
    "my_dictionary.load(dictionary_path=batches_train_path + '/mediaplanning_dictionary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test_path = '../data/tst/vw/data.vw.txt'\n",
    "batches_test_path = '../batches/tst/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(glob.glob(batches_test_path + \"/*.batch\")) < 1:\n",
    "    batch_vectorizer_test = artm.BatchVectorizer(data_path=data_test_path + '', collection_name='',\n",
    "                                            data_format='vowpal_wabbit', batch_size = 1000, \n",
    "                                            target_folder=batches_test_path)\n",
    "else:\n",
    "    batch_vectorizer_test = artm.BatchVectorizer(data_path=batches_test_path, \n",
    "                                            data_format='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary_ppmi = artm.Dictionary()\n",
    "dictionary_ppmi.gather(\n",
    "    data_path=batches_train_path,\n",
    "    cooc_file_path = \"../data/ppmi/ppmi.txt\",\n",
    "    vocab_file_path='../data/trn/UCI/vocab.news.txt',\n",
    "    symmetric_cooc_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengthes: 1000 29051\n"
     ]
    }
   ],
   "source": [
    "answers_test = helpers.loadFileAsStringArray('../data/labels/news.1lvlcat.tst.txt', True)\n",
    "id_test = helpers.loadFileAsStringArray('../data/labels/news.id.tst.txt', True)\n",
    "answers_train = helpers.loadFileAsStringArray('../data/labels/news.1lvlcat.trn.txt', True)\n",
    "id_train = helpers.loadFileAsStringArray('../data/labels/news.id.trn.txt', True)\n",
    "\n",
    "id2answer_tst = dict(zip(id_test,answers_test))\n",
    "id2answer_trn = dict(zip(id_train,answers_train))\n",
    "print 'Lengthes:',len(id2answer_tst),len(id2answer_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "бизнес культура медиа наука_и_техника общество_и_путешествия политика происшествия силовые_структуры спорт экономика_и_финансы\n"
     ]
    }
   ],
   "source": [
    "lvl1cats = sorted(list(set(id2answer_tst.values())))\n",
    "for cat in lvl1cats:\n",
    "    print cat,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hartm = artm.hARTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## первый уровень\n",
    "\n",
    "Код повторяет один из экспериментов Александра Романенко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category2number = dict(zip(lvl1cats,range(len(lvl1cats))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_matrix = []\n",
    "lenta_doc_ids = []\n",
    "topic_num = 11\n",
    "for idx,cat in id2answer_trn.iteritems():    \n",
    "    if category2number.has_key(cat):\n",
    "#         lenta_doc_ids += [idx]\n",
    "        temp_list = [1] * topic_num\n",
    "        # Здесь можно либо 0, либо -1\n",
    "        temp_list[category2number[cat]] = -100\n",
    "    else:\n",
    "        temp_list = [0] * topic_num\n",
    "    for x in range(10,topic_num):\n",
    "        temp_list[x] = -1000\n",
    "    lenta_doc_ids += [idx]\n",
    "    category_matrix += [temp_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subj_num_1 = len(lvl1cats)\n",
    "bckgrnd_num_1 = 1\n",
    "\n",
    "topics_names_lvl1 = [u'lvl1_'+ x for x in lvl1cats + ['background']]\n",
    "\n",
    "subj_topics = topics_names_lvl1[:10]\n",
    "bckgrnd_topics = topics_names_lvl1[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regularizers_lvl1 = []\n",
    "regularizers_lvl1 += [artm.SmoothSparsePhiRegularizer(name='SparseCategory', class_ids=['1lvlcat'], tau=0)]\n",
    "regularizers_lvl1 += [artm.DecorrelatorPhiRegularizer(name='DeccorTextSubj', class_ids=['text_ngramm'], tau=1000000)]\n",
    "regularizers_lvl1 += [artm.SmoothSparseThetaRegularizer(name='SST', tau=-20, doc_titles=lenta_doc_ids,\n",
    "                                                       doc_topic_coef=category_matrix)]\n",
    "\n",
    "\n",
    "\n",
    "regularizers_lvl1 += [artm.SmoothSparsePhiRegularizer(name='SmoothPhi', class_ids=['text_ngramm'], \n",
    "                                                 topic_names=bckgrnd_topics,\n",
    "                                                     tau=1)]\n",
    "\n",
    "regularizers_lvl1 += [artm.SmoothSparseThetaRegularizer(name='SmoothTheta', \n",
    "                                                        topic_names=bckgrnd_topics,\n",
    "                                                        tau=1)]\n",
    "\n",
    "scores_lvl1 = []\n",
    "scores_lvl1 += [artm.PerplexityScore(name='Perplexity', dictionary=my_dictionary, class_ids=['text_ngramm'])]\n",
    "scores_lvl1 += [artm.PerplexityScore(name='Perplexity_with_cat', dictionary=my_dictionary, class_ids=['text_ngramm','1lvlcat'])]\n",
    "scores_lvl1 += [artm.SparsityPhiScore(name='SparsityPhiText', class_id='text_ngramm')]\n",
    "scores_lvl1 += [artm.SparsityPhiScore(name='SparsityPhiCategory', class_id='1lvlcat')]\n",
    "scores_lvl1 += [artm.SparsityThetaScore(name='SparsityTheta')]\n",
    "scores_lvl1 += [artm.TopicKernelScore(name='TopicKernelText', probability_mass_threshold=0.1, class_id='text_ngramm')]\n",
    "scores_lvl1 += [artm.TopTokensScore(name='TopTokensText',class_id = 'text_ngramm', num_tokens=50)]\n",
    "scores_lvl1 += [artm.TopTokensScore(name='TopTokensScoreNgramm',class_id='text_ngramm', \n",
    "                               num_tokens=10, dictionary=dictionary_ppmi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artm.ARTM(num_topics=11, num_tokens=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lvl1 = hartm.add_level(num_topics=topic_num,topic_names=topics_names_lvl1)\n",
    "model_lvl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for r in regularizers_lvl1:\n",
    "    model_lvl1.regularizers.add(r) \n",
    "for s in scores_lvl1:\n",
    "    model_lvl1.scores.add(s)\n",
    "    \n",
    "model_lvl1.class_ids = {'text_ngramm': 1.0, '1lvlcat':50.0}\n",
    "model_lvl1.dictionary=my_dictionary\n",
    "model_lvl1.reuse_theta=True\n",
    "model_lvl1.cache_theta=True\n",
    "model_lvl1.num_document_passes=1\n",
    "model_lvl1.theta_columns_naming=u'title'\n",
    "model_lvl1.initialize(dictionary=my_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_lvl1.fit_offline(batch_vectorizer=batch_vectorizer_train, num_collection_passes=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## второй уровень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of subject topics\n",
    "subj_num_2 = 70\n",
    "# old background topics from the 1st level\n",
    "old_bckgrnd_num_2 = bckgrnd_num_1\n",
    "# new background topics\n",
    "bckgrnd_num_2 = 1\n",
    "\n",
    "num_topics_2 = subj_num_2 + old_bckgrnd_num_2 + bckgrnd_num_2\n",
    "topics_names_lvl2_subj = [u'lvl2_topic_subj_' + unicode(t) for t in range(subj_num_2)]\n",
    "topics_names_lvl2_old_bckgrnd = [u'lvl2_topic_old_bck_' + unicode(t) for t in range(old_bckgrnd_num_2)]\n",
    "topics_names_lvl2_bckgrnd = [u'lvl2_topic_bck_' + unicode(t) for t in range(bckgrnd_num_2)]\n",
    "topics_names_lvl2 = topics_names_lvl2_subj + topics_names_lvl2_bckgrnd + topics_names_lvl2_old_bckgrnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hartm.del_level(1)\n",
    "model_lvl2 = hartm.add_level(num_topics=num_topics_2,\n",
    "                             topic_names=topics_names_lvl2,\n",
    "                             parent_level_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for psi regularizer\n",
    "doc_topic_coef_1 = [[1] * (subj_num_2 + old_bckgrnd_num_2)  + [0] * bckgrnd_num_2]\n",
    "doc_topic_coef_2 = [[0] * (subj_num_2 + old_bckgrnd_num_2) + [1] * bckgrnd_num_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для улучшения модели более чётко сформулируем требования к фоновым темам. В этой модели фоновые темы с предыдущего уровня переносятся с помощью регуляризаторов матрицы пси с первого уровня на второй. Используется два регуляризатора: первый задаёт то, что ни у какой темы кроме old_background нет фоновых тем с первого уровня в качестве родителей, второй задаёт то, что у old_background тем на втором уровне в родителях только фоновая тема с первого уровня.\n",
    "\n",
    "Регуляризатор HierSp контролирует вид матрицы Пси, его влияние проследить сложно, но он очень сильно улучшает модель.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regularizers_lvl2 = []\n",
    "regularizers_lvl2 += [artm.DecorrelatorPhiRegularizer(name='DeccorText2', class_ids=['text_ngramm'],\n",
    "                                                     tau=1 * (10 ** 6))]\n",
    "\n",
    "regularizers_lvl2 += [artm.SmoothSparsePhiRegularizer(name='SparsePhi2_subj', tau=0,\n",
    "                                                       topic_names=topics_names_lvl2_subj)]\n",
    "\n",
    "regularizers_lvl2 += [artm.SmoothSparseThetaRegularizer(name='SparseTheta2_subj', tau=0,\n",
    "                                                       topic_names=topics_names_lvl2_subj)]\n",
    "\n",
    "regularizers_lvl2 += [artm.SmoothSparsePhiRegularizer(name='SmoothPhi2_bckgrnd', class_ids=['text_ngramm'], \n",
    "                                                 topic_names=topics_names_lvl2_bckgrnd, tau=10)]\n",
    "\n",
    "regularizers_lvl2 += [artm.SmoothSparseThetaRegularizer(name='SmoothTheta2_bckgrnd',  \n",
    "                                                        topic_names=topics_names_lvl2_bckgrnd,\n",
    "                                                        tau=10)]\n",
    "\n",
    "regularizers_lvl2 += [artm.HierarchySparsingThetaRegularizer(name='HierSp', tau=1000.0)]\n",
    "regularizers_lvl2 += [artm.SmoothSparseThetaRegularizer(name='SparsePsi_bckgrnd1',\n",
    "                                                        doc_titles=[u'lvl1_background'], \n",
    "                                                        doc_topic_coef=doc_topic_coef_1,\n",
    "                                                        tau=-10 ** 6)]\n",
    "\n",
    "regularizers_lvl2 += [artm.SmoothSparseThetaRegularizer(name='SparsePsi_bckgrnd2',\n",
    "                                                          tau=-10 ** 4,\n",
    "                                                          doc_titles=model_lvl1.topic_names[:-1],\n",
    "                                                          doc_topic_coef=doc_topic_coef_2)]\n",
    "\n",
    "\n",
    "scores_lvl2 = []\n",
    "scores_lvl2 += [artm.PerplexityScore(name='Perplexity', dictionary=my_dictionary, class_ids=['text_ngramm'])]\n",
    "scores_lvl2 += [artm.SparsityPhiScore(name='SparsityPhiText', class_id='text_ngramm')]\n",
    "scores_lvl2 += [artm.SparsityThetaScore(name='SparsityTheta')]\n",
    "scores_lvl2 += [artm.TopicKernelScore(name='TopicKernelText', probability_mass_threshold=0.1, class_id='text_ngramm')]\n",
    "scores_lvl2 += [artm.TopTokensScore(name='TopTokensText',class_id = 'text_ngramm', num_tokens=50)]\n",
    "scores_lvl2 += [artm.TopTokensScore(name='TopTokensScoreNgramm',class_id='text_ngramm', \n",
    "                               num_tokens=30, dictionary=dictionary_ppmi)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for r in regularizers_lvl2:\n",
    "    model_lvl2.regularizers.add(r, overwrite=True)\n",
    "\n",
    "for s in scores_lvl2:\n",
    "    model_lvl2.scores.add(s, overwrite=True)\n",
    "\n",
    "    \n",
    "model_lvl2.class_ids = {'text_ngramm' : 1.0}\n",
    "model_lvl2.dictionary=my_dictionary\n",
    "model_lvl2.reuse_theta=True\n",
    "model_lvl2.cache_theta=True\n",
    "model_lvl2.num_document_passes=1\n",
    "model_lvl2.theta_columns_naming=u'title'\n",
    "model_lvl2.initialize(dictionary=my_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_lvl2.fit_offline(batch_vectorizer_train, num_collection_passes=50)\n",
    "psi12 = (hartm.get_level(1).get_psi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## третий уровень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of subject topics\n",
    "subj_num_3 = 400\n",
    "# old background topics from the 1st level\n",
    "\n",
    "\n",
    "old_bckgrnd_num_3 = bckgrnd_num_1 + bckgrnd_num_2\n",
    "# new background topics\n",
    "bckgrnd_num_3 = 0\n",
    "\n",
    "num_topics_3 = subj_num_3 + old_bckgrnd_num_3 + bckgrnd_num_3\n",
    "topics_names_lvl3_subj = [u'lvl3_topic_subj_' + unicode(t) for t in range(subj_num_3)]\n",
    "topics_names_lvl3_old_bckgrnd = [u'lvl3_topic_old_bck_' + unicode(t) for t in range(old_bckgrnd_num_3)]\n",
    "topics_names_lvl3_bckgrnd = [u'lvl3_topic_bck_' + unicode(t) for t in range(bckgrnd_num_3)]\n",
    "topics_names_lvl3 = topics_names_lvl3_subj + topics_names_lvl3_bckgrnd + topics_names_lvl3_old_bckgrnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hartm.del_level(2)\n",
    "model_lvl3 = hartm.add_level(num_topics=num_topics_3,\n",
    "                             topic_names=topics_names_lvl3,\n",
    "                             parent_level_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_topic_coef_3_1 = [[1] * (subj_num_3 + bckgrnd_num_3 + bckgrnd_num_2)  + [0] * bckgrnd_num_1]\n",
    "doc_topic_coef_3_2 = [[0] * (subj_num_3 + bckgrnd_num_3 + bckgrnd_num_2) + [1] * bckgrnd_num_1]\n",
    "doc_topic_coef_3_3 = [[1] * (subj_num_3 + bckgrnd_num_3) + [0] * bckgrnd_num_2 + [1] * bckgrnd_num_1]\n",
    "doc_topic_coef_3_4 = [[0] * (subj_num_3 + bckgrnd_num_3) + [1] * bckgrnd_num_2 + [0] * bckgrnd_num_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularizers_lvl3 = []\n",
    "regularizers_lvl3 += [artm.DecorrelatorPhiRegularizer(name='DeccorText3', class_ids=['text_ngramm'],\n",
    "                                                     tau=1 * (10 ** 5))]\n",
    "\n",
    "\n",
    "regularizers_lvl3 += [artm.HierarchySparsingThetaRegularizer(name='HierSp', tau=1000.0)]\n",
    "\n",
    "regularizers_lvl3 += [artm.SmoothSparseThetaRegularizer(name='SparsePsi23_bckgrnd1',\n",
    "                                                        doc_titles=[u'lvl2_topic_old_bck_0'], \n",
    "                                                        doc_topic_coef=doc_topic_coef_3_1,\n",
    "                                                        tau=-10 ** 6)]\n",
    "\n",
    "regularizers_lvl3 += [artm.SmoothSparseThetaRegularizer(name='SparsePsi23_bckgrnd2',\n",
    "                                                          tau=-10 ** 4,\n",
    "                                                          doc_titles=model_lvl2.topic_names[:-1],\n",
    "                                                          doc_topic_coef=doc_topic_coef_3_2)]\n",
    "\n",
    "\n",
    "regularizers_lvl3 += [artm.SmoothSparseThetaRegularizer(name='SparsePsi23_bckgrnd3',\n",
    "                                                        doc_titles=[u'lvl2_topic_bck_0'], \n",
    "                                                        doc_topic_coef=doc_topic_coef_3_3,\n",
    "                                                        tau=-10 ** 6)]\n",
    "\n",
    "\n",
    "regularizers_lvl3 += [artm.SmoothSparseThetaRegularizer(name='SparsePsi23_bckgrnd4',\n",
    "                                                          tau=-10 ** 4,\n",
    "                                                          doc_titles=model_lvl2.topic_names[:-2] + [model_lvl2.topic_names[-1]],\n",
    "                                                          doc_topic_coef=doc_topic_coef_3_4)]\n",
    "\n",
    "\n",
    "scores_lvl3 = []\n",
    "scores_lvl3 += [artm.PerplexityScore(name='Perplexity', dictionary=my_dictionary, class_ids=['text_ngramm'])]\n",
    "scores_lvl3 += [artm.SparsityPhiScore(name='SparsityPhiText', class_id='text_ngramm')]\n",
    "scores_lvl3 += [artm.SparsityThetaScore(name='SparsityTheta')]\n",
    "scores_lvl3 += [artm.TopicKernelScore(name='TopicKernelText', probability_mass_threshold=0.1, class_id='text_ngramm')]\n",
    "scores_lvl3 += [artm.TopTokensScore(name='TopTokensText',class_id = 'text_ngramm', num_tokens=50)]\n",
    "scores_lvl3 += [artm.TopTokensScore(name='TopTokensScoreNgramm',class_id='text_ngramm', \n",
    "                               num_tokens=30, dictionary=dictionary_ppmi)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r in regularizers_lvl3:\n",
    "    model_lvl3.regularizers.add(r, overwrite=True)\n",
    "\n",
    "for s in scores_lvl3:\n",
    "    model_lvl3.scores.add(s, overwrite=True)\n",
    "\n",
    "    \n",
    "model_lvl3.class_ids = {'text_ngramm' : 1.0}\n",
    "model_lvl3.dictionary=my_dictionary\n",
    "model_lvl3.reuse_theta=True\n",
    "model_lvl3.cache_theta=True\n",
    "model_lvl3.num_document_passes=1\n",
    "model_lvl3.theta_columns_naming=u'title'\n",
    "model_lvl3.initialize(dictionary=my_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lvl3.fit_offline(batch_vectorizer_train, num_collection_passes=50)\n",
    "psi23 = (hartm.get_level(2).get_psi())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity 2628.37120757\n",
      "Coherence 1.69810605049\n",
      "Phi Sparsity 0.924357623277\n",
      "Theta Sparsity 0.897116356616\n"
     ]
    }
   ],
   "source": [
    "print 'Perplexity', model_lvl3.score_tracker['Perplexity'].value[-1]\n",
    "print 'Coherence', model_lvl3.score_tracker['TopTokensScoreNgramm'].average_coherence[-1]\n",
    "\n",
    "print 'Phi Sparsity', model_lvl3.score_tracker['SparsityPhiText'].value[-1]\n",
    "print 'Theta Sparsity', model_lvl3.score_tracker['SparsityTheta'].value[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi = hartm.get_phi(class_ids=['text_ngramm'])\n",
    "theta = hartm.get_theta()\n",
    "psi12 = hartm.get_level(1).get_psi()\n",
    "psi23 = hartm.get_level(2).get_psi()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
